{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upobLF-7XNHo"
   },
   "source": [
    "# CS97 HW3 - Binary Classification Comparative Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpZ2eJ6AXNHp"
   },
   "source": [
    "For this project we're going to attempt the binary classification of a dataset using multiple methods and compare results.\n",
    "\n",
    "Our goals for this project is to introduce you to several of the most common classification techniques, how to perform them and tweak parameters to optimize the outcome, how to produce and interpret results, and compare performance. You will be asked to analyze your findings and provide explanations for the observed performance.\n",
    "\n",
    "Specifically you will be asked to classify whether a <b>patient is suffering from heart disease</b> based on a host of potential medical factors.\n",
    "\n",
    "<b><u>DEFINITIONS</b></u>\n",
    "\n",
    "\n",
    "<b> Binary Classification:</b>\n",
    "In this case a complex dataset has an added 'target' label with one of two options. Your learning algorithm will try to assign one of these labels to the data.\n",
    "\n",
    "<b> Supervised Learning:</b>\n",
    "The data is fully supervised, which means it's been fully labeled and we can trust the veracity of the labeling. The target is to predict the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CImOo6xKXNHq"
   },
   "source": [
    "## 0.1. Background: The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrWZoTnkXNHr"
   },
   "source": [
    "For this exercise we will be using a subset of the UCI Heart Disease dataset, leveraging the fourteen most commonly used attributes. All identifying information about the patient has been scrubbed.\n",
    "\n",
    "The dataset includes 14 columns. The information provided by each column is as follows:\n",
    "<ul>\n",
    "    <li><b>age:</b> Age in years</li>\n",
    "    <li><b>sex:</b> (1 = male; 0 = female)</li>\n",
    "    <li><b>cp:</b> Chest pain type (0 = asymptomatic; 1 = atypical angina; 2 = non-anginal pain; 3 = typical angina)</li>\n",
    "    <li><b>trestbps:</b> Resting blood pressure (in mm Hg on admission to the hospital)</li>\n",
    "    <li><b>cholserum:</b> Cholestoral in mg/dl</li>\n",
    "    <li><b>fbs:</b> Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)</li>\n",
    "    <li><b>restecg:</b> Resting electrocardiographic results (0= showing probable or definite left ventricular hypertrophy by Estes' criteria; 1 = normal; 2 = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV))</li>\n",
    "    <li><b>thalach:</b> Maximum heart rate achieved</li>\n",
    "    <li><b>exang:</b> Exercise induced angina (1 = yes; 0 = no)</li>\n",
    "    <li><b>oldpeakST:</b> Depression induced by exercise relative to rest</li>\n",
    "    <li><b>slope:</b> The slope of the peak exercise ST segment (0 = downsloping; 1 = flat; 2 = upsloping)</li>\n",
    "    <li><b>ca:</b> Number of major vessels (0-4) colored by flourosopy</li>\n",
    "    <li><b>thal:</b> 1 = normal; 2 = fixed defect; 3 = reversable defect</li>\n",
    "    <li><b><u>Sick:</u></b> Indicates the presence of Heart disease (True = Disease; False = No disease). It is the label.</li>\n",
    "</ul>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNbi-JouXNHs"
   },
   "source": [
    "## 0.2. Loading Essentials and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TC3VZ8Z5XNHs"
   },
   "outputs": [],
   "source": [
    "#Here are a set of libraries we imported to complete this assignment.\n",
    "#Feel free to use these or equivalent libraries for your implementation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XvJNZ0fzXNHt"
   },
   "outputs": [],
   "source": [
    "# Helper function allowing you to export a graph\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qqtIPRdzXNHt"
   },
   "outputs": [],
   "source": [
    "# Helper function that allows you to draw nicely formatted confusion matrices\n",
    "def draw_confusion_matrix(y, yhat, classes):\n",
    "    '''\n",
    "        Draws a confusion matrix for the given target and predictions\n",
    "        Adapted from scikit-learn and discussion example.\n",
    "    '''\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    matrix = confusion_matrix(y, yhat)\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    num_classes = len(classes)\n",
    "    plt.xticks(np.arange(num_classes), classes, rotation=90)\n",
    "    plt.yticks(np.arange(num_classes), classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIdoNvYlXNHv"
   },
   "source": [
    "## [20pt] Part 1.  Load the Data and Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh-zKMpIXNHv"
   },
   "source": [
    "### 1.1. Let's first load our dataset (heartdisease.csv) so we'll be able to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5220iz66XNHw"
   },
   "outputs": [],
   "source": [
    "'''NOTE FROM TA's'''\n",
    "'''Please use this website https://htmtopdf.herokuapp.com/ipynbviewer/\n",
    "  to convert ipynb file of this colab (File -> download as ipynb) to pdf,\n",
    "  instead of ctrl+p this page because it will not format beutifully\n",
    "  and it'll be difficult for us to grade'''\n",
    "\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1Madtt_YvvLiHLjaC1KpOReO1V9ClQw6t') # heartdisease.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_USIcXSXNHw"
   },
   "source": [
    "### 1.2. Now that our data is loaded, let's take a closer look at the dataset we're working with. Use the head method and the describe method to display some of the rows and undertand the summary of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "16IWwsPNXNHx"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''\n",
    "# Hint: use the head() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KhmoqRF-XNHx"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''\n",
    "# Hint: use the describe() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyWv4-1MXNHx"
   },
   "source": [
    "### 1.3. Sometimes data will be stored in different formats (e.g., string, date, boolean), but many learning methods work strictly on numeric inputs. Call the info method to determine the datafield type for each column. Are there any that are problemmatic and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Iq-5BOGwXNHy"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX4ZzNgBXNHy"
   },
   "source": [
    "**Your answer:**  (Hint: we can handle numeric variables, such as int and float, but we cannot directly handle bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFrIlNZiXNHy"
   },
   "source": [
    "### 1.4. Determine whether we're dealing with any null value (NaN). If so, report on which columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JDWVKylnXNHy"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''\n",
    "# Hint: isnull() (from HW1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B1auWy4XNHz"
   },
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuaEfczwXNHz"
   },
   "source": [
    "### 1.5. Before we begin our analysis we need to fix the field(s) that will be problematic. We replace our boolean 'sick' variable into a numeric variable, named as 'target'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l7M85tmEXNH0"
   },
   "outputs": [],
   "source": [
    "data['target'] = (data['sick']).astype(int)\n",
    "del data['sick']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHt0eh5XNH1"
   },
   "source": [
    "### 1.6. We also want to make sure we are dealing with a balanced dataset. In this case, we want to confirm whether or not we have an equitable number of  sick and healthy individuals to ensure that our classifier will have a sufficiently balanced dataset to adequately classify the two. Let's count the number of sick and healthy individuals and report your results. Then answer whether it is balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3ZGEJO7NXNH1"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsVUEWxHXNH1"
   },
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhn7Ji2xXNH2"
   },
   "source": [
    "### 1.7. If the dataset is imbalanced, can you name one possible solution to address it? (This question does not mean this dataset is balanced or imbalanced, it is an independent question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJF7vDomXNH2"
   },
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2O11gYjXNH2"
   },
   "source": [
    "### 1.8. Now that we have our dataframe prepared, let's start analyzing our data. For this next question let's look at the correlations of our features to our target value. (hint: one possible approach you can use is corr() method from HW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "V17nzhW-XNH2"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXj-rYO2XNH3"
   },
   "source": [
    "## [25pt] Part 2. Prepare the Data and run a KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9M2_3ZaXNH3"
   },
   "source": [
    "Before running our various learning methods, we need to do some additional preparation to finalize our data. We will save the label as a separate dataframe and split the dataset into training set and test set. Then, you wil prepare 2 batches of data: one is simply the raw data that hasn't gone through any additional pre-processing; the other will be the data after preprocessing. We will then feed both of these datasets into a classifier to showcase how important this step can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nn4GrfrEXNH4"
   },
   "source": [
    "### 2.1. Save the label column as a separate array (let's name it as data_target) and then drop the label column from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UboQCizJXNH4"
   },
   "outputs": [],
   "source": [
    "'''Your code goes below here'''\n",
    "# Hint: drop() (check HW1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOhmb1QAXNH4"
   },
   "source": [
    "### 2.2. First Create your \"raw\" unprocessed training data by dividing your dataframe into training and testing cohorts, with your training cohort consisting of 80% of your total dataframe (hint: use the train_test_split method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "H34h6dkFXNH5"
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw, target_raw, target_raw_test = train_test_split(data, data_target, test_size = 0.2, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIC_923dXNH5"
   },
   "source": [
    "### 2.3. Output the resulting shapes of your training and testing samples to confirm that your split was successful. How many training samples and test samples do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1eKCeZWdXNH5"
   },
   "outputs": [],
   "source": [
    "print(train_raw.shape, target_raw.shape)\n",
    "print(test_raw.shape, target_raw_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZQ0cdJVXNH5"
   },
   "source": [
    "### 2.4. In lecture we learned about K-Nearest Neighbor. One thing we noted was because KNN's rely on Euclidean distance, they are highly sensitive to the relative magnitude of different features. Let's see that in action! Implement a K-Nearest Neighbor algorithm on our data. For this initial implementation simply use the default setting (K=5). Refer to the [KNN Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) for details on implementation. Report on the accuracy of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "RKxhsC3YXNH6"
   },
   "outputs": [],
   "source": [
    "''' Hint:\n",
    "1.) create KNeighborsClassifier() object\n",
    "2.) fit data\n",
    "3.) use the predict() method to predict the test data, and assign to variable \"raw_predicted\" since we will use \"raw_predicted\" in below cells\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57cM958DXNH6"
   },
   "source": [
    "### 2.5. Print the accuracy, precision, recall, f1-score of the model, and draw the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9wMqVY0kXNH7"
   },
   "outputs": [],
   "source": [
    "def print_four_metrics(target, predicted):\n",
    "    print(\"%-12s %f\" % ('Accuracy:', metrics.accuracy_score(target, predicted)))\n",
    "    print(\"%-12s %f\" % ('Precision:', metrics.precision_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
    "    print(\"%-12s %f\" % ('Recall:', metrics.recall_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
    "    print(\"%-12s %f\" % ('F1 Score:', metrics.f1_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
    "\n",
    "print_four_metrics(target_raw_test, raw_predicted)\n",
    "draw_confusion_matrix(target_raw_test, raw_predicted, ['Healthy', 'Sick'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euhRpTfGXNH7"
   },
   "source": [
    "### 2.6. Now try to improve k-NN's performance by data preprocessing. You can drop the top-1, or top-2, or top-3 useless features according to the correlation matrix we have obtained (the 1/2/3 features that are most negatively correlated with the label), normalize the numerical features, use one-hot encoding for the categorical features, etc. Please refer to HW1 for data preprocessing. Note you don't need to do data augmentation. Your f1-score need to be higher than 0.85 to get the full score for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fJ9CtNMXNH7"
   },
   "source": [
    "#### Pipeline / preprocessing process. Please name the data after preprocessing as \"improved_data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "KoL3Lg0AXNH7"
   },
   "outputs": [],
   "source": [
    "'''Hint: As long as you follow all the strategies in the above instructions, your f1-score will be higher than 0.85.'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8DEZBqkXNH7"
   },
   "source": [
    "#### take a look at your prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VT_rt86CXNH8"
   },
   "outputs": [],
   "source": [
    "improved_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE8IPNcOXNH8"
   },
   "source": [
    "### 2.7. Now split your pipelined data into an 80/20 split and again run the same KNN, draw the same confusion matrix. Discuss how you improved the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOpjIgPyXNH8"
   },
   "source": [
    "#### Split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "Jh_pUWvgXNH8"
   },
   "outputs": [],
   "source": [
    "train, test, target, target_test = train_test_split(improved_data, data_target, test_size = 0.2, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL3GcREcXNH8"
   },
   "source": [
    "#### Run KNN as before. Do not change the default k=5 in k-NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "2I8r-Uf_XNH9"
   },
   "outputs": [],
   "source": [
    "''' Hint:\n",
    "1.) create KNeighborsClassifier() object\n",
    "2.) fit data\n",
    "3.) use the predict() method to predict the test data, and assign to variable \"predicted\" since we will use \"predicted\" in below cells\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report accuracy, precision, recall, f1-score, and draw the confusion matrix as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yHl1nid0ahcV"
   },
   "outputs": [],
   "source": [
    "print_four_metrics(target_test, predicted)\n",
    "draw_confusion_matrix(target_test, predicted, ['Healthy', 'Sick'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXrtGXCrXNH9"
   },
   "source": [
    "**Your answer:** [Explain what strategies you used to improve the performance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBt8ToBSXNH-"
   },
   "source": [
    "### 2.8. Model Selection on K.  As discussed in class, the KNN Algorithm includes an n_neighbors (k) attribute that specifies how many neighbors to use when developing the cluster. (The default value is 5, which is what your previous model used.) Lets now try n_neighbors (k) values of: 1, 2, 3, 5, 7, 9, 10, 20, and 200. Run your model for each value and print the f1-score for each. What is the best k among these choices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xFJPujbdXNH-"
   },
   "outputs": [],
   "source": [
    "k_values = [1, 2, 3, 5, 7, 9, 10, 20, 200]\n",
    "\n",
    "for k in k_values:\n",
    "    # Hint: when creating the KNN object, assign parameter \"n_neighbors\" to k\n",
    "    # referece: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "    # Hint: you only need to print the f1-score. You do not need to print other metrics. You can use the improved_data after your preprocessing\n",
    "    '''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7iqIU64XNH-"
   },
   "source": [
    "## [45pt] Part 3. Additional Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWvtbg9HXNH-"
   },
   "source": [
    "So we have a model that seems to work well. But let's see if we can do better! You can continue using the data you preprocessed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvJdjHa_XNH_"
   },
   "source": [
    "### [25pt] 3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-B2oidUXNH_"
   },
   "source": [
    "Let's now try another classifier we introduced in lecture, one that's well known for handling linear models: Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brk8-ivaXNIA"
   },
   "source": [
    "### 3.1.1. Implement a logistical regression classifier. Review the [Logistical Regression Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for how to implement the model. Print accuracy, precision, recall, f1-score, plot the ROC curve, and report the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_fw7xKryXNIA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1.) create LogisticRegression() object\n",
    "2.) fit your train data\n",
    "3.) use the predict() method to predict the test data, and assign to variable \"log_predicted\"\n",
    "4.) use predict_proba(test)[:,1] and assign to variable \"log_score\"\n",
    "  NOTE: predict() returns the predicted classification (0 or 1), \n",
    "  while predict_proba() returns the predicted probability (a float between 0 and 1)\n",
    "  NOTE: predict_proba() will return\n",
    "  [probability of data belonging to class 0, probability of data belonging to class 1]\n",
    "  and we want to get probability of data belonging to class 1. That's why we slice\n",
    "  the array by only getting the column 1\n",
    "'''\n",
    "'''Your code goes below here'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NIM0qoO3XNIB"
   },
   "outputs": [],
   "source": [
    "# Print the performance, plot the ROC curve, and print the area under ROC\n",
    "def plot_roc_curve(target, score):\n",
    "    fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(target, score)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
    "    plt.title(\"ROC curve with Logistic Regression\")\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.show()\n",
    "    # Print the area under ROC, which is also called \"AUC (Area Under the ROC curve)\"\n",
    "    aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
    "    print('AUC of ROC: ', aucroc)\n",
    "\n",
    "print_four_metrics(target_test, log_predicted)\n",
    "plot_roc_curve(target_test, log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98zo095zXNIB"
   },
   "source": [
    "### 3.1.2. Let's tweak a few settings. The default model is using the L2-regularization (ridge). Let's set penalty to None and rerun your model. Let's see how your results change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "2IGnInZOXNIC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1.) create LogisticRegression() object, while specify its parameter \"penalty\" to None\n",
    "2.) fit your train data\n",
    "3.) use the predict() method to predict the test data, and assign to variable \"log_predicted\"\n",
    "4.) use predict_proba(test)[:,1] and assign to variable \"log_score\"\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iZ3DNvaYXNIC"
   },
   "outputs": [],
   "source": [
    "# Print accuracy, precision, recall, and F1 score\n",
    "print_four_metrics(target_test, log_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DojefdaJXNIC"
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve and print the area under ROC\n",
    "plot_roc_curve(target_test, log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-sbzd6eXNIC"
   },
   "source": [
    "### 3.1.3 Rerun your logistic classifier, but modify the penalty = 'l1', solver = 'liblinear', and again report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "D3CmXqHHXNID"
   },
   "outputs": [],
   "source": [
    "''' repeat the same process as 3.1.3 but change parameters as the question specifies'''\n",
    "'''Your code goes below here'''\n",
    "# Run logistic regression here\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score. Feel free to use the print_four_metrics function\n",
    "\n",
    "# Plot ROC curve and print the area under ROC. Feel free to use the plot_roc_curve function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QYPIbXQXNID"
   },
   "source": [
    "###  3.1.4. We played around with different penalty terms (none, L1 etc.) Print the parameters of your model that uses the L1-norm (LASSO). Describe the purpose of using a penalty term. (Whether it improves your results depend on your preprocessing, so it is fine if it does not improve your results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EFlnXmBMXNID"
   },
   "outputs": [],
   "source": [
    "# Hint: Use print(your_model_name.coef_) to print the parameters of your model.\n",
    "# Do you see any zero? Those are related to the penalty term.\n",
    "'''Your code goes below here'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WriGeLtSXNID"
   },
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx89pWRLXNIE"
   },
   "source": [
    "### [20pt] 3.2. SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOMAEmShXNIE"
   },
   "source": [
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. Given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane to classify the data. In two dimentional space this hyperplane is a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr0AGpavXNIF"
   },
   "source": [
    "### 3.2.1 Implement a Support Vector Machine classifier on your pipelined data. Review the [SVM Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for how to implement a model. For this implementation you can simply use the default settings, but set probability = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1spdtl7oXNIG"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1.) create SVC() object, while specify its parameter \"probability\" to \"True\"\n",
    "2.) fit your train data\n",
    "3.) predict the test data. and assign to a variable\n",
    "  because we will use it in the next cell\n",
    "4.) use svm.predict_proba(test)[:,1] and assign to a variable\n",
    "  bacause we will use it in the next cell\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGfIBazWXNIG"
   },
   "source": [
    "### 3.2.2 Print the accuracy, precision, recall, F1 Score, plot the ROC curve, and print and the area under ROC Curve of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ivAB6kkPXNIG"
   },
   "outputs": [],
   "source": [
    "# Feel free to use print_four_metrics and plot_roc_curve functions\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xJevqNvXNIH"
   },
   "source": [
    "### 3.2.3.  Rerun your SVM, but now modify the kernel to 'linear'. Again print your accuracy, precision, recall, F1-score, plot the new ROC curve, and report the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "PMD7ZATxXNIH"
   },
   "outputs": [],
   "source": [
    "# run SVM\n",
    "'''\n",
    "1.) create SVC() object like 3.2.2, but change parameter 'kernel' to 'linear' as the question specifies\n",
    "2.) fit your train data\n",
    "3.) predict the test data. and assign to a variable\n",
    "  because we will use it in below cell\n",
    "4.) use svm.predict_proba(test)[:,1] and assign to a variable\n",
    "  bacause we will use it in below cell\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Z9-S1O-OXNII"
   },
   "outputs": [],
   "source": [
    "''' repeat the same process as 3.2.2'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the default kernel (\"rbf\") and the \"linear\" kernel, which one is better? You can look up the [SVM kernel's documentation](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_kernels.html#sphx-glr-auto-examples-svm-plot-svm-kernels-py). Is the decision boundary more like a linear hyperplane or a circle? (You can just draw the conclusion from which kernel is better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnajoFPIXNII"
   },
   "source": [
    "## [10pt + bonus 10pt] Part 4: Cross Validation and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tyy0SM1sXNIJ"
   },
   "source": [
    "You have practiced a number of different classification techniques. Based on these experiments you should have settled on a particular model that performs most optimally on the chosen dataset.\n",
    "\n",
    "Before our work is done though, we want to ensure that our results are not the result of the random sampling of our data we did with the train-test split. We will conduct a k-fold cross-validation of our top two performing models, assess their cumulative performance across folds, and determine the best model for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QPgGP5TXNIJ"
   },
   "source": [
    "### [10pt] 4.1. Select your top 2 performing models and run a K-Fold Cross Validation on both (use 10 folds). Replace the corresponding code in the cell below. Report your best performing model. You can use accuracy to select the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AeLheTOGXNIJ"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# First we define our cross-validation model parameters. In this case we're going to use KFold, with 10 splits\n",
    "# where we first shuffle our data before splitting it, and use a random seed to ensure a consistent repeatable shuffle\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# replace the two models below with what you picked\n",
    "log_model_kfold = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "svc_model_kfold = SVC(kernel = 'linear', probability = True)\n",
    "\n",
    "# Finally we pull it all together. We call cross val score to generate an accuracy performance score for our model\n",
    "# we define our learning model, data, labels, and cross-val splitting strategy (all defined previously)\n",
    "log_results_kfold = model_selection.cross_val_score(log_model_kfold, train, target, cv=kfold)\n",
    "svc_results_kfold = model_selection.cross_val_score(svc_model_kfold, train, target, cv=kfold)\n",
    "\n",
    "# Because we're collecting results from all runs, we take the mean value\n",
    "print(\"For Logistic Regression our mean accuracy across folds is: %.2f%%\" % (log_results_kfold.mean() * 100.0))\n",
    "print(\"For an SVM Regression our mean accuracy across folds is: %.2f%%\" % (svc_results_kfold.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dRvgdjjXNIK"
   },
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrjTZGxjXNIK"
   },
   "source": [
    "### [bonus 10pt] 4.2. use 10-fold cross validation to select the best hyperparameter $\\lambda$ (1/C) in logistic regression with l2 penalty. What is the best $\\lambda$ you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pbZ3MgGvXNIK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  This is similar to 4.1\n",
    "  Hint: create a bunch of lambdas value\n",
    "  then you can use a loop,\n",
    "  assign parameter \"C\" to be \"1 / (lambda)\"\n",
    "  and print out cross_val_score().\n",
    "  Also, specify which lambda is the best one in your opinion\n",
    "'''\n",
    "'''Your code goes below here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
