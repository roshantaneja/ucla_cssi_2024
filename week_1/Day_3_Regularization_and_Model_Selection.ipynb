{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHeN3ilmZapM"
      },
      "source": [
        "# Regularization and Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMm2jZ7WN-Js"
      },
      "source": [
        "## Remember the 3 integral steps!\n",
        "\n",
        "\n",
        "1.   Model construction\n",
        "2.   Model usage\n",
        "3.   Model selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tunyMC1zOqLz"
      },
      "source": [
        "##We've talked about step 1 (Model construction)...\n",
        "\n",
        "We use our training data to find our estimates\n",
        "\n",
        "##And we've talked about step 2 (Model usage)...\n",
        "\n",
        "We use our data against test data\n",
        "\n",
        "##...So what about model selection?\n",
        "\n",
        "How do we know which model will be the best fit for our data? How do we prevent overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgscR3trPGWq"
      },
      "source": [
        "## Variable selection\n",
        "\n",
        "We can use stepwise variable selection to select the best predictors using stepwise variable selection & cross validation!\n",
        "\n",
        "In stepwise variable selection we iteratively find the optimal set of predictors by slowly building up how many predictors we are using.\n",
        "\n",
        "1. Start with no predictors\n",
        "2. Choose the predictor with the highest R^2 value (or other metric)\n",
        "3. Select the next predictor that increases the R^2 value until no new candidates remain that will increase the R^2 (again, or other metric we are using the evaluate our model's accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSeyjImROVF"
      },
      "source": [
        "#Variable (forward) selection example!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMH1qrk5Qrv_"
      },
      "source": [
        "Download the .csv file from this link here: https://drive.google.com/file/d/10UeKpTSuqPnTeydHmqrSzYGbvVoCX4zF/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Kw62lTRGzf"
      },
      "source": [
        "Import your libraries..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAwOWjclQhD9",
        "outputId": "51caf242-aa58-4827-ee17-9d3704a4660d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      7\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE8aotSVjZvk"
      },
      "source": [
        "Before going forward, let's uninstall and reinstall scikit learn\n",
        "This is because colab's default sklearn is version 0.22.2, and we want 0.24.2 for this since 0.22.2 does not have sequential feature selection!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "39Ek2SynjZOo",
        "outputId": "85475802-369e-4397-8634-d21ae7f1e426"
      },
      "outputs": [],
      "source": [
        "#only do this once - don't re-run it after restarting your runtime\n",
        "\n",
        "!pip uninstall scikit-learn -y\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import sklearn\n",
        "\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oU303k7Td_o"
      },
      "source": [
        "Load our dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPUaPJzERQez"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/student_scores_extended.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99DMfXqqThVS"
      },
      "source": [
        "Explore our dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Z4Dg1EAwT6NH",
        "outputId": "264b6cb4-91d0-4551-8cce-797e575929c6"
      },
      "outputs": [],
      "source": [
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga6f5cT_kh48",
        "outputId": "8c553c51-43f3-440e-da65-1718e206827e"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qte-2IPKUIRw"
      },
      "source": [
        "Let's plot each attribute and see what it looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5KQJ7Uo0UMqk",
        "outputId": "1f59357f-fe6d-4369-fad0-6f4d2a2506b7"
      },
      "outputs": [],
      "source": [
        "attributes = ['Previous score', 'Prereqs taken', 'ID number', 'Hours']\n",
        "\n",
        "for property in attributes:\n",
        "  dataset.plot(x=property, y='Scores', style='o')\n",
        "  plt.title(property + ' vs Percentage')\n",
        "  plt.xlabel(property)\n",
        "  plt.ylabel('Percentage Score')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTecwQjUjEF"
      },
      "source": [
        "**What do you notice about these plots already?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1R3f7O_gXAe"
      },
      "source": [
        "Now let's do forward selection! First, get out training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "snG19yNIgbEr",
        "outputId": "3d721123-003b-49f8-f7a8-7f1c3817011b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # remember this from yesterday?\n",
        "\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F0o2wU7hp1x"
      },
      "source": [
        "Next, let's decide what model we are using (let's go with linear regression!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUDjvVRhhmks"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU6YEMLchtj1"
      },
      "source": [
        "Now, let's implement our step forward feature selector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHrv66XgfXH",
        "outputId": "1a37aefc-5149-4984-e14c-a2d9ab3abb3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "selector = SequentialFeatureSelector(\n",
        "    lr,\n",
        "    n_features_to_select=None,\n",
        "    direction='forward',\n",
        "    scoring='r2',\n",
        "    cv = 5\n",
        ")\n",
        "\n",
        "selector.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5TAbr8MivEb"
      },
      "source": [
        "Now, let's print out which columns (features) were chosen as the optimal featuers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwaT1ADBkCco",
        "outputId": "a31d25ce-5a6d-4689-a5f9-b89c21aca27b"
      },
      "outputs": [],
      "source": [
        "selector.get_support()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqMCyP6kJz3"
      },
      "source": [
        "This means it chose 1,3 as our optimal features! `n_features_to_select=None` means it chooses half the features by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grnn7F3zuJGJ"
      },
      "source": [
        "**Do those results make sense to you?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNqhWCcbkTyH"
      },
      "source": [
        "You can also do `selector.transform(X)` to directly get a transformed version without the other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_EI9JTqkc3O",
        "outputId": "d5ec5509-8dd3-4596-80e5-a574f21c9d8f"
      },
      "outputs": [],
      "source": [
        "selector.transform(X_train).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TLHUGdauX-L"
      },
      "source": [
        "# Cross Validation\n",
        "\n",
        "We want to prevent overfitting! So we can cross validate our models onto various data sets and average our performance. There are various methods explained more in lecture\n",
        "\n",
        "*   K-fold\n",
        "*   Leave-One-Out\n",
        "\n",
        "Let's take a look at a dummy example...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g3ROe22GR_u",
        "outputId": "fb82fcdc-4bbd-4836-93d9-6d404fd2ab3f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "\n",
        "kf = KFold(n_splits=2)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "     X_train, X_test = X[train_index], X[test_index]\n",
        "     y_train, y_test = y[train_index], y[test_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z141sUcvcX8"
      },
      "source": [
        "#Regularization\n",
        "\n",
        "We don't want to deal with extremes/outliers that may skew our data. Regularization helps us modify our loss function (how much our predictions differed from the actual values). We can use two types of regularization methods. This also helps with overfitting!\n",
        "\n",
        "1.   L1 - Lasso Regularization\n",
        "2.   L2 - Ridge Regularization\n",
        "\n",
        "Let's use MSE (Mean Squared Error) as our loss function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbJ8qG2c9TUd"
      },
      "source": [
        "##Lasso Regularization (L1)\n",
        "\n",
        "AKA Least Absolute Shrinkage and Selection Operator\n",
        "\n",
        "We want to reduce overfitting and control our regularization parameter lambda. Lasso regularization takes the magnitude of our lambda into account by adding a penalty to our loss function which is the absolute value of the magnitude of the coefficient. This method basically shrinks our data until it reaches some middle point. Beware it can lead to a sparse model (small number of coefficients)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd0mTphh-zUD"
      },
      "source": [
        "Let's look at an example in code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43xHhDNB-08D"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ26zHv6vqgO"
      },
      "outputs": [],
      "source": [
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpWFYfjB-6xg",
        "outputId": "073dbef6-41a5-41f6-fbd5-4c63fdfd46e7"
      },
      "outputs": [],
      "source": [
        "l1 = Lasso(alpha=0.1)\n",
        "l1.fit(X_train, y_train)\n",
        "l1.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAtItjW2AU-1",
        "outputId": "6d0a4462-f5b1-4aa7-bdbe-5312495b1e60"
      },
      "outputs": [],
      "source": [
        "print(l1.coef_) # prints the parameters/coefficients for each of our features that will reduce our loss function\n",
        "print(l1.intercept_) # intercept for our loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIpNfrUOB0aZ"
      },
      "source": [
        "Note: Lasso regularization tends to make coefficients zero which ends up reducing features. So it can help us with model/feature selection like we just explored!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ca3qHyaBVal"
      },
      "source": [
        "#Ridge Regularization (L2)\n",
        "\n",
        "Similar to lasso except lasso tends to make its coefficients zero whereas ridge will never do that. In ridge, our penalty is the square of our coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HipCoS99CGwT"
      },
      "source": [
        "Let's look at an example in code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKpc0wokCHNo"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sitGRG4bCIyN",
        "outputId": "84c83e82-f600-48a0-c4c8-a4ac6bd0daec"
      },
      "outputs": [],
      "source": [
        "l2 = Ridge(alpha=0.1)\n",
        "l2.fit(X_train, y_train)\n",
        "l2.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDjQQdUCPWk",
        "outputId": "418d0ea8-9359-41fc-cf0a-77fed0332d42"
      },
      "outputs": [],
      "source": [
        "print(l2.coef_)\n",
        "print(l2.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUjE1UivCTeT"
      },
      "source": [
        "**Let's compare the results from Ridge to our results from Lasso!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OHeN3ilmZapM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
